

数值分析专题目录：

https://reborn.blog.csdn.net/article/details/80933338





强化学习学习！

行为策略：用来与环境互动产生数据的策略，训练中决策

目标策略：在行为策略产生的数据中不断学习、优化，即学习训练完毕后拿去应用的策略。 





学习问题的利用和探索·

--利用行为策略 来保持探索性，提供多样化的数据。而优化是采用目标策略

onpolicy 的目标策略和行为策略是同一个策略，好处，简单粗暴。只学习局部最优

offpolicy将目标策略和行为策略分开，保持探索的同时，求导全局最优。

https://www.zhihu.com/question/57159315/answer/465865135



A Painless Q-learning Tutorial (一个 Q-learning 算法的简明教程)

https://blog.csdn.net/itplus/article/details/9361915

意思：你看不懂-

Qlearning和Sarsa的区别到底是什么？为什么说Qlearning勇敢而Sarsa胆小

谨慎？https://blog.csdn.net/weixin_45485946/article/details/105295402

引用的---Bourne强化学习笔记2：彻底搞清楚什么是Q-learning与Sarsa

https://blog.csdn.net/linyijiong/article/details/81607691

可以看到，Q-learning寻找到一条全局最优的路径，因为虽然Q-learning的行为策略（behavior）是基于 ε-greedy策略，但其目标策略（target policy）只考虑最优行为；而Sarsa只能找到一条次优路径，这条路径在直观上更加安全，这是因为Sarsa（其目标策略和行为策略为同一策略）考虑了所有动作的可能性（ ε-greedy），当靠近悬崖时，由于会有一定概率选择往悬崖走一步，从而使得这些悬崖边路的价值更低。


五、总结

Q-learning虽然具有学习到全局最优的能力，但是其收敛慢；而Sarsa虽然学习效果不如Q-learning，但是其收敛快，直观简单。因此，对于不同的问题，我们需要有所斟酌
————————————————
版权声明：本文为CSDN博主「Bourne_Boom」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/linyijiong/article/details/81607691



学习强化学习代码的例子：

https://www.cnblogs.com/hhh5460/p/10134018.html

超级多参考资料：6.1基于值函数逼近的强化学习方法 （1）

https://zhuanlan.zhihu.com/p/432414363

Conda 创建虚拟环境

conda create --name 环境名 python=版本号

conda info --envs

Activate xx

deactivate xx



5.1 跟三叔说的一些事情：

自己学习------

人是社交关系的，但晚上还是很寂寞，所以晚上还是要 ---想1怎么说话，怎么做事，怎么做等等



我是那种不喜欢独处的人，---跟ss聊了后，知道！



