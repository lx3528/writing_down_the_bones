参考笔记：

https://blog.csdn.net/weixin_44356285/article/details/89464114



# CS 294: Deep Reinforcement Learning Note（1）

# https://zhuanlan.zhihu.com/p/29080505

https://zhuanlan.zhihu.com/p/32598322

![image-20220502073512595](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502073512595.png)



有些是需要fullly observe才能看见

![image-20220502073751294](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502073751294.png)

在full observe下，s3和s1独立。所以满足。markov性质

imitation learning是什么：

收集人类数据做imitation learning

![image-20220502073940888](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502073940888.png)



在没有专家数据的话，

--使用奖励函数

![image-20220502074035293](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502074035293.png)



防止路中间，因为reward也会变低。装叉是低reward

![image-20220502074158984](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502074158984.png)



![image-20220502074222187](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502074222187.png)

没说observe



pomdp  partially observed mdp 因为看到的不是最终状态，所以多了一个转移矩阵



![image-20220502074551193](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502074551193.png)







![image-20220502074819259](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502074819259.png)



![image-20220502075035896](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502075035896.png)



![image-20220502075126155](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502075126155.png)



![image-20220502075158258](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502075158258.png)



特征值1，酚酞分布，可能存在稳态，t到正无穷，

![image-20220502075449425](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502075449425.png)

dagger？





![image-20220502075520051](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502075520051.png)





![](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502075538738.png)







![image-20220502075633823](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502075633823.png)



![image-20220502080011686](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502080011686.png)



哪个部分比较贵？

![image-20220502080233060](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502080233060.png)



因为不能计算梯度：

![image-20220502080325369](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502080325369.png)



![image-20220502081627365](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502081627365.png)



![image-20220502081753381](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502081753381.png)



![image-20220502082803737](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502082803737.png)



![image-20220502082833911](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502082833911.png)



大致总结：

![image-20220502083208389](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083208389.png)



![image-20220502083242664](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083242664.png)





![image-20220502083345903](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083345903.png)

dyna用模型拟合经验，作为数据，加到模型无关的学习上



![image-20220502083513382](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083513382.png)



![image-20220502083536738](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083536738.png)

![image-20220502083555519](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083555519.png)



tradeoff

![image-20220502083650497](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083650497.png)



![image-20220502083706266](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083706266.png)



![image-20220502083724675](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083724675.png)



神经网络收敛到复杂函数

![image-20220502083855758](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502083855758.png)

pg需要很多样本

value function fitting 如果error是零，可以得到最好的reward。但如果value function不是0，那不能达到最好expected reward。

 ![image-20220502084422265](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502084422265.png)

![image-20220502084727045](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502084727045.png)

？？



![image-20220502084924325](/Users/lixiang/Documents/typora/learn/0415learnthing/294-2.assets/image-20220502084924325.png)















